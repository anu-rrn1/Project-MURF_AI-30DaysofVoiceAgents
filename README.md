**üéôÔ∏è Voice Conversational Bot with Chat History:**
1. This project is a real-time AI voice assistant that:
2. Listens to your voice üé§
3. Converts it to text using AssemblyAI Speech-to-Text
4. Sends the text + chat history to Google Gemini API for contextual conversation ü§ñ
5. Converts the LLM‚Äôs reply to speech using Murf API üîä
6. Plays the AI's voice reply in the browser
7. Automatically starts recording again after the AI finishes speaking, enabling a hands-free, continuous conversation.

**üõ† Technologies Used:**
**Frontend:**
- HTML, CSS, JavaScript (Vanilla)
- Web Audio API (MediaRecorder)
- Fetch API for server communication
**Backend:**
- Python FastAPI (REST API server)
- Requests (for calling AssemblyAI, Gemini, Murf APIs)
- CORS Middleware for frontend-backend communication
**APIs & AI Models:**
- AssemblyAI ‚Üí Speech-to-Text (STT)
- Google Gemini ‚Üí Large Language Model
- Murf AI ‚Üí Text-to-Speech (TTS)
**Datastore:**
- In-memory Python dictionary (prototype-friendly) for session-based chat history

**üèó Architecture:**
[User Voice] 
     ‚Üì
Browser (MediaRecorder) 
     ‚Üì
POST /agent/chat/{session_id}  
     ‚Üì
[Backend: FastAPI]
  1Ô∏è‚É£ AssemblyAI API ‚Üí Transcribe
  2Ô∏è‚É£ Fetch chat history for session_id
  3Ô∏è‚É£ Append user message to history
  4Ô∏è‚É£ Gemini API ‚Üí Get LLM response
  5Ô∏è‚É£ Append AI response to history
  6Ô∏è‚É£ Murf API ‚Üí Convert to Speech
     ‚Üì
Send {gemini_text, audio_url} back
     ‚Üì
Browser plays audio ‚Üí Restarts recording

**‚ú® Features:**
- üé§ Voice Input: Record audio directly in browser
- üó£ Speech-to-Text via AssemblyAI
- üß† Context-Aware Conversations using Gemini API with chat history
- üîä Text-to-Speech using Murf API
- ‚ôª Continuous Hands-Free Chat ‚Äî auto-restarts recording after AI speaks
- üí¨ Session-based Chat History using session ID in URL
- üåê Fully web-based ‚Äî no app installation required

**How to run this on your laptop:**
- ‚öôÔ∏è Environment Variables
Create a .env file in the backend folder:
=>
ASSEMBLYAI_API_KEY=your_assemblyai_key
GEMINI_API_KEY=your_gemini_api_key
MURF_API_KEY=your_murf_api_key

**üöÄ Setup & Run Instructions**
- 1Ô∏è‚É£ Clone Repository
=>
- git clone https://github.com/yourusername/voice-gemini-murf-chat.git
- cd voice-gemini-murf-chat
- 2Ô∏è‚É£ Backend Setup
- cd backend
- pip install fastapi uvicorn python-dotenv requests
- Create .env with your API keys.
- Run the backend:
- uvicorn main:app --reload
- By default, it runs at:
http://127.0.0.1:8000
- 3Ô∏è‚É£ Frontend Setup
Just open index.html in your browser, or serve it via a simple HTTP server:
cd frontend
python -m http.server 5500
Then visit:
http://localhost:5500/index.html?session_id=123
(session_id can be any unique string to start a new conversation session)

**üì° API Endpoints:**
POST /agent/chat/{session_id}
Description: Handles the full flow (Audio ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio Output) while keeping track of chat history.
Request:
Path Parameter: session_id (string)
Body: file (audio/webm)
Response:
{
  "gemini_text": "Hello! How can I help you?",
  "audio_url": "https://murf.ai/generated_audio.mp3"
}

**üîÆ Future Improvements:**
- Replace in-memory chat history with Redis or MongoDB for persistence
- Add speaker diarization for multi-user conversations
- Support multiple languages
- Deploy on cloud (Render, Vercel, Railway, etc.)
